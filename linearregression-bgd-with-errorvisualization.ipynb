alpha = 0.001
h = [] # for pridicted value
error = [] # for error value
iteration = 10
for j in range(iteration):
  total_error = 0.0
  for i in range(x.shape[0]):
    h.append(W[0] + W[1]*x[i])
    total_error += (h[i] - y[i]) ** 2
  # print(h)
  error.append(total_error / x.shape[0])
  # Calculate Gradient
  dw0_sum = 0.0
  for i in range(x.shape[0]):
    dw0_sum += (h[i]-y[i])
  dw1_sum = 0.0
  for i in range(x.shape[0]):
    dw1_sum += (x[i]*(h[i] - y[i]))

  # Update parameter
  W[0] = W[0] - (alpha * 2 * dw0_sum) / x.shape[0]
  W[1] = W[1] - (alpha * 2 * dw1_sum) / x.shape[0]
  # print(W)
  plt.plot(x, h)
  plt.legend([i+1 for i in range(iteration)])
  h.clear()
plt.scatter(x, y)
plt.xlabel("Pizza Size (inch)")
plt.ylabel("Price (TK)")
plt.title("Linear Regression using Batch Gradient Descent")
plt.grid()
plt.show()
plt.plot([i+1 for i in range(iteration)], error)
plt.xlabel("Epoch")
plt.ylabel("Average Squared Error")
plt.title("Error Curve Of Batch Gradient Descent")
plt.grid()
plt.show()
